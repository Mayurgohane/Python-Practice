{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from transformers import AutoModel, AutoFeatureExtractor"
      ],
      "metadata": {
        "id": "2_VeWAX4xrik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Pre Trained Model and Feature Extractor"
      ],
      "metadata": {
        "id": "-809GvYcz-Yg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"gouthaml/raos-virtual-try-on-model\" #DeepVTO Model\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "feature_extractor = AutoFeatureExtractor.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "0eAnrA0rxrlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare the Dataset"
      ],
      "metadata": {
        "id": "qHh3SJNk0Jhl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionDataset(Dataset):\n",
        "    def __init__(self, images, targets, transform=None):\n",
        "        self.images = images\n",
        "        self.targets = targets\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.images[idx]).convert(\"RGB\")\n",
        "        target = Image.open(self.targets[idx]).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            target = self.transform(target)\n",
        "        return image, target\n",
        "\n",
        "# Path\n",
        "train_images = [\"path\"]\n",
        "train_targets = [\"path\"]\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "train_dataset = FashionDataset(train_images, train_targets, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)"
      ],
      "metadata": {
        "id": "GfLC5J7wxroj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chnages in Model Architecture"
      ],
      "metadata": {
        "id": "9otWxQA50kMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDeepVTOModel(nn.Module):\n",
        "    def __init__(self, pretrained_model):\n",
        "        super(CustomDeepVTOModel, self).__init__()\n",
        "        self.base_model = pretrained_model\n",
        "        self.unet = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.base_model(x).last_hidden_state\n",
        "        features = features.permute(0, 2, 1).contiguous().view(features.size(0), 768, 14, 14)\n",
        "        x = self.unet(features)\n",
        "        return x\n",
        "\n",
        "custom_model = CustomDeepVTOModel(model)"
      ],
      "metadata": {
        "id": "G2ENemCnxrrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving New Model"
      ],
      "metadata": {
        "id": "H9lizWQ_1BCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "custom_model = CustomDeepVTOModel(model)"
      ],
      "metadata": {
        "id": "UWgpRX0V0_UK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Loop"
      ],
      "metadata": {
        "id": "zyUX-tPX0rrp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(custom_model.parameters(), lr=1e-4)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    custom_model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, targets in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        inputs = feature_extractor(images, return_tensors=\"pt\").pixel_values\n",
        "        outputs = custom_model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}')\n",
        "\n"
      ],
      "metadata": {
        "id": "Ksxz70hVxrvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download new model for future use"
      ],
      "metadata": {
        "id": "-LiXC0Cr1Ist"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(custom_model.state_dict(), 'fine_tuned_deepvto_model.pth')"
      ],
      "metadata": {
        "id": "uzDC1wVNxrxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-siZI71-xrzt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}