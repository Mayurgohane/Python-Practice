# -*- coding: utf-8 -*-
"""Pandas.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oQnEgMBa_OHlibze-FNfrWR6lhV7mHkw
"""

#Load csv data
data = pd.read_csv(" ")

#Load table data
data = pd.read_table(" ")

#Load data by sep "t"
data = pd.read_csv(" ",sep='\t')

#First rows
data.head()

#Tail data
data.tail()

#Diverse samples
data.sample()

#Shape of data
data.shape()

#Info
data.info()

#Basic stats
data.describe()

#Includes Object
data.describe(include='object')

"""Accessing Columns"""

#Acessing single column
data['Column_Name']

#Finding no.of unique values from each column
data.nunique()

#Finding the count of unique values from each column
data['Column_name'].value_counts().head()

#Mode
data.column_name.mode()

#Mean
data.column_name.mean()

# selecting multiple columns
data = chips_data[['column_name1','column_name2']]

"""Using .loc[] for Label-Based Selection

"""

# Access row with index label 1
data.loc[1]

# For selecting specific rows and columns
data.loc[3:6,['column_1','column_2']]

# For selecting a single cell from a specific row and column
data.loc[100,'item_name']

# For selecting a row values of a specific row
data.loc[100,:]

# For seleting all column values of a specific column
data.loc[:,'item_name']

"""Using .iloc[] for Integer-Based Selection"""



"""Setting Index"""

data.set_index('column_name').head()

data.set_index('column_name',inplace=True)

data.reset_index(inplace=True)

#checking missing data
data.column_name.isna()

# Rows where the specific column value is missing.
data[data.column_name.isna()].head()

#count of missing values
data.isna().sum()

# missing data count for one column
data.column_name.isna().sum()

#drops the rows where any of the column value is missing
data.dropna().head()

#drop column
udata.dropna(subset=['column_name']).head()

#drop column
udata.dropna(subset=['column_name'], inplace=True)

#drop the rows where all of the specified column values are missing
data.dropna(how='all').head()

#To check the count of duplicated rows
data.duplicated().sum()

# Results the duplicated rows when there is an any other row with exact match of
duplicates = data[data.duplicated()]

# Results the duplicated columns when there is a match of the specified columns
id_price_duplicates = data[data.duplicated(subset=['column1','column2'])]

#Drop the duplicated rows using
data.duplicated().sum()

#Drop & save
data.drop_duplicates(inplace=True)

#convert all the values in item_name to upper case
data.column_name.str.upper()

# saving the original data with the modified one, as it doesn't have inplace opti
data.column_name = data.column_name.str.upper()

# Using contains to find how many rows have item names with chicken
data.column_name.str.contains('CHICKEN').sum()

# As now we know about string operations, we can also utilize that here to remove
data.column_name.str.replace('$','')

data.column_name.str.replace('$','').astype('float')

# Apply the function row-wise.
data['column_name'] = data.apply(column_name, axis=1)

#apply a function to each element in the entire DataFrame
def add_10(x):
 return x + 10
# Apply the function to the entire DataFrame
df = df.applymap(add_10)

# if we don't want colors reported and shape reported columns
data.drop(['column1','column2'], axis=1, inplace=True)

# Sample DataFrames with the same column names
data1 = {'A': [1, 2, 3], 'B': [4, 5, 6], 'C':[1,2,3]}
data2 = {'A': [7, 8, 9], 'B': [10, 11, 12], 'D':[1,2,3]}

df1 = pd.DataFrame(data1)
df2 = pd.DataFrame(data2)

# Concatenate df1 and df2 horizontally (along columns) with same column names
horizontal_concat = pd.concat([df1, df2], axis=0)

#Inner Join
# Sample DataFrames
df1 = pd.DataFrame({'ID': [1, 2, 3], 'Name': ['Alice', 'Bob', 'Charlie']})
df2 = pd.DataFrame({'ID': [2, 3, 4], 'Age': [25, 30, 22]})

# Inner join on 'ID'
result = pd.merge(df1, df2, on='ID', how='inner')

#Left join

result = pd.merge(df1, df2, on='ID', how='left')

#Merging for columns with mismatched names

# Sample DataFrames
df1 = pd.DataFrame({'ID1': [1, 2, 3], 'Name': ['Alice', 'Bob', 'Charlie']})
df2 = pd.DataFrame({'ID2': [2, 3, 4], 'Age': [25, 30, 22]})

# Inner join on 'ID'
result = pd.merge(df1, df2, left_on='ID1', right_on='ID2', how='inner')

#Merging one df column with other df index

# Sample DataFrames
df1 = pd.DataFrame({'ID': [1, 2, 3], 'Name': ['Alice', 'Bob', 'Charlie']})
df2 = pd.DataFrame({'ID': [2, 3, 4], 'Age': [25, 30, 22]})

# Setting ID Column as the index for the df1 table
df1.set_index('ID',inplace=True)

# Inner join on index for the left table and 'ID' column for the right table
result = pd.merge(df1, df2, left_index=True, right_on='ID', how='inner')

#Group By

# Sample DataFrame
data = {'Class': ['A', 'B', 'A', 'B', 'A', 'B'],
 'Gender': ['Male', 'Male', 'Female', 'Female', 'Male', 'Female'],
 'Math_Score': [85, 92, 78, 89, 90, 86],
 'English_Score': [88, 94, 80, 92, 92, 88],
 'Physics_Score': [78, 90, 85, 92, 88, 84]}
df = pd.DataFrame(data)

# Grouping by 'Category'
grouped_data = df.groupby('Gender')

# Choosing sales column to compare with grouped data and using sum function
# This gives the total sales for each category.
total_sales = grouped_data['Math_Score'].sum()

#Group with single column and apply to entire Dataframe

# Grouping by 'Class' and 'Gender'
grouped_data = df.groupby('Gender')

# Applying the mean aggregation function to all numeric columns
aggregated_data = grouped_data.mean()

#GroupBy with multiple columns

# Grouping by 'Class' and 'Gender' and calculating statistics
grouped_data = df.groupby(['Class', 'Gender'])

# Calculate the mean for Math_score
agg_results = grouped_data['Math_Score'].mean()

# Grouping by 'Class' and 'Gender' and calculating statistics
grouped_data = df.groupby(['Class', 'Gender'])

# Calculate the mean for all numeric columns
agg_results = grouped_data.mean()

#Apply multiple aggregate functions to the grouped data
# Grouping by 'Class' and 'Gender' and calculating statistics
grouped_data = df.groupby(['Class', 'Gender'])

# Calculate the mean, min, and max scores for Math_score
agg_results = grouped_data.Math_Score.agg(['mean', 'min', 'max'])

#Apply multiple aggregate functions for selected columns

# Applying aggregation functions to 'Math_Score' and 'Physics_Score'
aggregated_data = grouped_data.agg({
 'Math_Score': ['mean', 'min', 'max'],
 'Physics_Score': ['mean', 'min', 'max']
})

#Sorting Data
chips_data.sort_values(by='item_price')

#One-Hot Encoding using pd.get_dummies

# Sample DataFrame with a categorical column
data = {'Category': ['A', 'B', 'A', 'C', 'B'],
 'Count':[1,2,3,4,5]}
df = pd.DataFrame(data)

# Perform one-hot encoding
encoded_df = pd.get_dummies(df, columns=['Category'])

#Label Encoding using Category type

# Sample DataFrame with a categorical column
data = {'Category': ['A', 'B', 'A', 'C', 'B']}
df = pd.DataFrame(data)

# Perform label encoding
df['Category_Encoded'] = df['Category'].astype('category').cat.codes









