# -*- coding: utf-8 -*-
"""IMDB_Movie_Reviews (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l6xQCjL8fF1RsOreL5uMxut9BRI-Cftg

**Problem Statement- we have to predict number of positive & negative reviews based on sentiments by using different classification models**
"""

from nltk.tokenize import word_tokenize
from nltk.tokenize import sent_tokenize
from nltk.corpus import stopwords
from nltk import WordNetLemmatizer
from nltk import PorterStemmer
import nltk
import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')

data=pd.read_csv('Data.csv')
data

data.shape

data.describe()

data['sentiment'].value_counts()

data.info

data.isnull().sum()

"""Removing Punctuation"""

from string import punctuation

def pun(x):
    return ''.join([i for i in x if i not in punctuation])

data['Punct']=data['review'].apply(lambda x:pun(x))

"""Removing Emoji"""

!pip install emoji

import emoji

data['Emoji']=data['Punct'].apply(lambda x:emoji.replace_emoji(x,''))

data

"""Tokenization, Lemmitization, Stemming"""

nltk.download('stopwords')
nltk.download('punkt')
nltk.download('wordnet')

LE=WordNetLemmatizer()

sw=stopwords.words('english')

Ps=PorterStemmer()

def preprocess(x):
  a=x.lower()
  b=''.join([i for i in a if i not in punctuation])
  c=word_tokenize(b)
  d=' '.join([Ps.stem(i) for i in c if i not in stopwords.words('english')])
  return d

data['Preprocess']=data['Emoji'].apply(lambda x:preprocess(x))
data

"""Dropping Unnessary Columns"""

data.drop(['review', 'sentiment','Punct','Emoji'], axis=1,inplace=True)
data

"""Vectorizer"""

from sklearn.feature_extraction.text import TfidfVectorizer

Tif=TfidfVectorizer()

new=Tif.fit_transform(data['Preprocess']).toarray()

NewData=pd.DataFrame(new,columns=Tif.get_feature_names_out())
NewData.head(3)

TargetData=pd.read_csv('Data.csv')
TargetData

TargetData = TargetData.drop('review', axis=1)
TargetData

"""Label Encoding"""

from sklearn.preprocessing import LabelEncoder

label_encoder = LabelEncoder()

TargetData['encoded_sentiments'] = label_encoder.fit_transform(TargetData['sentiment'])

TargetData

TargetData = TargetData.drop('sentiment', axis=1)
TargetData

"""Final Dataset"""

FinalData=pd.concat((NewData,TargetData),axis=1)
FinalData.head()

"""Dividing Data into X & y"""

X=FinalData.drop('encoded_sentiments',axis=1)
y=FinalData['encoded_sentiments']

X

y

"""Dividing Data into train_test"""

from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=0)

"""Logistic Regression"""

from sklearn.linear_model import LogisticRegression

LR=LogisticRegression(max_iter=500,multi_class='multinomial')

LR.fit(x_train,y_train)

y_pred=LR.predict(x_test)

y_test

from sklearn.metrics import accuracy_score,confusion_matrix,classification_report

accuracy_score(y_test,y_pred)*100

confusion_matrix(y_test,y_pred)

"""Multinomial Naive Bayes"""

from sklearn.naive_bayes import MultinomialNB

Nb=MultinomialNB()

Nb.fit(x_train,y_train)

d=Nb.predict(x_test)

accuracy_score(y_test,d)*100

from sklearn.metrics import classification_report,confusion_matrix

print(classification_report(y_test,d))

"""Randomised Seach Cross Validation (MultinomialNB)"""

from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import uniform, randint

param_dist = {
    'alpha': uniform(0.1, 10.0),
}

Nb=MultinomialNB()

random_search = RandomizedSearchCV(Nb, param_distributions=param_dist, random_state=42)

random_search.fit(X, y)

best_params = random_search.best_params_
best_score = random_search.best_score_
print("Best Parameters:", best_params)
print("Best Score:", best_score)

"""Random Forest Classifier"""

from sklearn.ensemble import RandomForestClassifier

RF=RandomForestClassifier(n_estimators=200,max_depth=3)

RF.fit(x_train.values,y_train.values)

r=RF.predict(x_test)

accuracy_score(y_test,r)*100

"""Decision Tree Classifier"""

from sklearn.tree import DecisionTreeClassifier

DC=DecisionTreeClassifier()

DC.fit(x_train.values,y_train.values)

g=DC.predict(x_test)

accuracy_score(y_test,g)*100

"""GaussianNB"""

from sklearn.naive_bayes import GaussianNB

model=GaussianNB()

model.fit(x_train,y_train)

pred=model.predict(x_test)

accuracy_score(y_test,pred)*100

"""Support Vector Machine"""

from sklearn.svm import SVC

svm_classifier = SVC(kernel='linear', C=1.0)

svm_classifier.fit(x_train, y_train)

y_pred = svm_classifier.predict(x_test)

accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy*100)

"""From above it's concluded that **Support Vector Machine gave accuracy of 83.5**"""